- we want to download everything in parallel
- ideally even git clones
- we want git clones to come to us as fast as possible, we don't need all history
- we want to bring inbound gems into a incoming directory for processing
- we focus on creating a global cache that has all the gems perfectly prepared, we don't care about re-use between different versions there, and every ruby version/arch gets its own expanded cache
- we attempt to do expensive operations in bulk such as mass unpacking of gems
- we do everything in parallel that can be parallel
- version number resolution works by casing the strings 1.1.1 into int64 at different orders of magnitude so that version comparisons are just int comparisons. 
- final bundle install step is to bring all gems to ./.bundle in the most efficient operation imaginable
- the installation process involves compilation. We attempt to have compilation happen while its not blocking other operations, but also only one compilation at a time
- we have a book keeping object that governs the worker pools and that's present during each step (fetch, extract, compile, install) and recieves the tasks for each phase from the workers. 
- i suspect that we need to fork of a worker for compilation which we then have to communicate with via some rpc format. simple "-> CALL method, <- RESULT:\n...." type line protocol through stdin/out might work well enough there. 
- cache validity is defined by cached tree + spec marshal + versioned manifest, scoped by ABI (with `gem.build_complete` for native extensions)
- cached manifests are versioned JSON with deterministic ordering and a file list for fast materialization
- git cache slugs are deterministic hashes of the normalized source URI with collision detection + telemetry
- legacy cached entries without a manifest remain read-compatible but emit telemetry for deprecation

